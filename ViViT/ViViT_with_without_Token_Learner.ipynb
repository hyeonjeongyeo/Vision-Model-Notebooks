{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ViViT with/without Token Learner\n",
        "\n",
        "This notebook explores the effect of **Token Learner** put in **ViViT**. \n",
        "\n",
        "The datasets used for training are from **MedMNIST 3D**, which contains medical 3D images with different types of classes. The model structure was tested on patch size 8 and 16, and token learner was put in the middle (half point of the transformer blocks). AdamW optimization method was used for regulralization and the learning rate was reduced on plateau.\n",
        "\n",
        "### The Result\n",
        "\n",
        "<p align=\"center\">\n",
        " <img src = \"./ViViT/img/vivit_tl_nodulemnist3d.png\", height=\"200x\", width=\"500px\">\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        " <img src = \"./ViViT/img/vivit_tl_organmnist3d.png\", height=\"200x\", width=\"500px\">\n",
        "</p>\n",
        "\n",
        "The overall performance of the model with token learner was better than the naive model in validation accracy and loss over epochs. Also, there was no signs of overfitting with token learner even though the training time was shortened. The result shows that with token learners models learn faster, without significant risk of overfitting.\n",
        "\n",
        "All of the result graphs are displayed on [TensorBoard](https://tensorboard.dev/experiment/nYVP58K4Q1GEuWLbkWBFow/). \n",
        "\n",
        "### References :\n",
        "1. Paper : [TokenLearner: Adaptive Space-Time Tokenization for Videos](https://proceedings.neurips.cc/paper/2021/file/6a30e32e56fce5cf381895dfe6ca7b6f-Paper.pdf) \n",
        "1. Paper : [ViViT: A Video Vision Transformer](https://arxiv.org/abs/2103.15691)\n",
        "1. Codes : https://keras.io/examples/vision/token_learner/\n",
        "1. Codes : https://keras.io/examples/vision/vivit/\n",
        "1. Blog : https://ai.googleblog.com/2021/12/improving-vision-transformer-efficiency.html"
      ],
      "metadata": {
        "id": "EB33Fi7KAG2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settings & Downloads"
      ],
      "metadata": {
        "id": "n7rq-OEgUAm4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZtbVjUq-AExq"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U tensorflow\n",
        "!pip install -q -U tensorboard\n",
        "!pip install -q tensorflow-gpu\n",
        "!pip install -q tensorflow-addons  # for AdamW Optimizer.\n",
        "!pip install -q medmnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "DqvmU0lGFpDY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import logging\n",
        "import medmnist\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "# Setting seed for reproducibility\n",
        "SEED = 2023\n",
        "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
        "keras.utils.set_random_seed(SEED)\n",
        "\n",
        "\n",
        "# Single device checking\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    DEVICE_NAME = \"/gpu:0\"\n",
        "    print(\"Currently running on GPU\")\n",
        "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "else:  \n",
        "    DEVICE_NAME = \"/cpu:0\"\n",
        "    print(\"Currently running on CPU\")\n",
        "\n",
        "\n",
        "# Refrain from verbose logging\n",
        "logging.disable(logging.WARNING)\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
      ],
      "metadata": {
        "id": "_rz3tfjbpx69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb65f15-e790-4845-e975-ecfdedbc3b02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently running on GPU\n",
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameters"
      ],
      "metadata": {
        "id": "yg3ems49U4RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA\n",
        "# https://github.com/MedMNIST/MedMNIST/blob/main/medmnist/dataset.py\n",
        "DATASET_INFOS = ((\"organmnist3d\", 11), \n",
        "                 (\"nodulemnist3d\", 2),\n",
        "                 (\"adrenalmnist3d\", 2),\n",
        "                 (\"fracturemnist3d\", 3),\n",
        "                 (\"vesselmnist3d\", 2),\n",
        "                 (\"synapsemnist3d\", 2))  # (dataset_name, num_classes)\n",
        "INPUT_SHAPE = (28, 28, 28, 1)\n",
        "BATCH_SIZE = 64\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "\n",
        "# OPTIMIZER\n",
        "LEARNING_RATE = 1e-4\n",
        "WEIGHT_DECAY = 1e-5\n",
        "\n",
        "# TRAINING\n",
        "EPOCHS = 60  # will use early stop method.\n",
        "\n",
        "# TUBELET EMBEDDING & TOKENLEARNER\n",
        "PATCH_SIZES = [8, 16]\n",
        "\n",
        "# ViViT ARCHITECTURE\n",
        "LAYER_NORM_EPS = 1e-6\n",
        "PROJECTION_DIM = 128\n",
        "NUM_HEADS = 8\n",
        "NUM_LAYERS = 8\n",
        "MLP_UNITS = [\n",
        "    PROJECTION_DIM * 2,\n",
        "    PROJECTION_DIM,\n",
        "]"
      ],
      "metadata": {
        "id": "ZMMTUMVGT2GS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- ### Load and prepare the CIFAR-10 dataset -->\n",
        "\n"
      ],
      "metadata": {
        "id": "hwbZz15TT5BO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_prepare_dataset(data_info: dict):\n",
        "    \"\"\"Utility function to download the dataset.\n",
        "\n",
        "    Arguments:\n",
        "        data_info (dict): Dataset metadata.\n",
        "    \"\"\"\n",
        "    data_path = keras.utils.get_file(\n",
        "        origin=data_info[\"url\"], md5_hash=data_info[\"MD5\"]\n",
        "    )\n",
        "\n",
        "    with np.load(data_path) as data:\n",
        "        # Get videos\n",
        "        train_videos = data[\"train_images\"]\n",
        "        valid_videos = data[\"val_images\"]\n",
        "        test_videos = data[\"test_images\"]\n",
        "\n",
        "        # Get labels\n",
        "        train_labels = data[\"train_labels\"].flatten()\n",
        "        valid_labels = data[\"val_labels\"].flatten()\n",
        "        test_labels = data[\"test_labels\"].flatten()\n",
        "\n",
        "    return (\n",
        "        (train_videos, train_labels),\n",
        "        (valid_videos, valid_labels),\n",
        "        (test_videos, test_labels),\n",
        "    )"
      ],
      "metadata": {
        "id": "H5amdASAdg4m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def preprocess(frames: tf.Tensor, label: tf.Tensor):\n",
        "    \"\"\"Preprocess the frames tensors and parse the labels.\"\"\"\n",
        "    # Preprocess images\n",
        "    frames = tf.image.convert_image_dtype(\n",
        "        frames[\n",
        "            ..., tf.newaxis\n",
        "        ],  # The new axis is to help for further processing with Conv3D layers\n",
        "        tf.float32,\n",
        "    )\n",
        "    # Parse label\n",
        "    label = tf.cast(label, tf.float32)\n",
        "    return frames, label\n",
        "\n",
        "\n",
        "def prepare_dataloader(\n",
        "        videos: np.ndarray,\n",
        "        labels: np.ndarray,\n",
        "        loader_type: str = \"train\",\n",
        "        batch_size: int = BATCH_SIZE,\n",
        "    ):\n",
        "    \"\"\"Utility function to prepare the dataloader.\"\"\"\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((videos, labels))\n",
        "\n",
        "    if loader_type == \"train\":\n",
        "        dataset = dataset.shuffle(BATCH_SIZE * 2)\n",
        "\n",
        "    dataloader = (\n",
        "        dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        .batch(batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "def get_dataloaders(dataset_name):\n",
        "    # Get the metadata of the dataset\n",
        "    info = medmnist.INFO[dataset_name]\n",
        "\n",
        "    # Get the dataset\n",
        "    prepared_dataset = download_and_prepare_dataset(info)\n",
        "    (train_videos, train_labels) = prepared_dataset[0]\n",
        "    (valid_videos, valid_labels) = prepared_dataset[1]\n",
        "    (test_videos, test_labels) = prepared_dataset[2]\n",
        "\n",
        "    # Prepare DataLoaders\n",
        "    trainloader = prepare_dataloader(train_videos, train_labels, \"train\")\n",
        "    validloader = prepare_dataloader(valid_videos, valid_labels, \"valid\")\n",
        "    testloader = prepare_dataloader(test_videos, test_labels, \"test\")\n",
        "\n",
        "    return (trainloader, validloader, testloader)"
      ],
      "metadata": {
        "id": "5IavAYqZfvec"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n"
      ],
      "metadata": {
        "id": "by13GmpAUKfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TubeletEmbedding(layers.Layer):\n",
        "    def __init__(self, embed_dim, patch_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.projection = layers.Conv3D(\n",
        "            filters=embed_dim,\n",
        "            kernel_size=patch_size,\n",
        "            strides=patch_size,\n",
        "            padding=\"valid\",\n",
        "        )\n",
        "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
        "\n",
        "    def call(self, videos):\n",
        "        projected_patches = self.projection(videos)\n",
        "        flattened_patches = self.flatten(projected_patches)\n",
        "        return flattened_patches"
      ],
      "metadata": {
        "id": "wZqHBgYW0SuZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        _, num_tokens, _ = input_shape\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_tokens, output_dim=self.embed_dim\n",
        "        )\n",
        "        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
        "\n",
        "    def call(self, encoded_tokens):\n",
        "        # Encode the positions and add it to the encoded tokens\n",
        "        encoded_positions = self.position_embedding(self.positions)\n",
        "        encoded_tokens = encoded_tokens + encoded_positions\n",
        "        return encoded_tokens"
      ],
      "metadata": {
        "id": "JnxqYVDs0TRT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TokenLearner Module"
      ],
      "metadata": {
        "id": "gfrw4qYOUSuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def token_learner(inputs, num_tokens):\n",
        "    # Layer normalize the inputs.\n",
        "    x = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(inputs)  # (B, T, H, W, C)\n",
        "\n",
        "    # Applying Conv3D => Reshape => Permute\n",
        "    # The reshape and permute is done to help with the next steps of\n",
        "    # multiplication and Global Average Pooling.\n",
        "    attention_maps = keras.Sequential(\n",
        "        [\n",
        "            # 3 layers of conv with gelu activation as suggested\n",
        "            # in the paper.\n",
        "            layers.Conv3D(\n",
        "                filters=num_tokens,\n",
        "                kernel_size=(3, 3, 3),\n",
        "                activation=tf.nn.gelu,\n",
        "                padding=\"same\",\n",
        "                use_bias=False,\n",
        "            ),\n",
        "            layers.Conv3D(\n",
        "                filters=num_tokens,\n",
        "                kernel_size=(3, 3, 3),\n",
        "                activation=tf.nn.gelu,\n",
        "                padding=\"same\",\n",
        "                use_bias=False,\n",
        "            ),\n",
        "            layers.Conv3D(\n",
        "                filters=num_tokens,\n",
        "                kernel_size=(3, 3, 3),\n",
        "                activation=tf.nn.gelu,\n",
        "                padding=\"same\",\n",
        "                use_bias=False,\n",
        "            ),\n",
        "            # This conv layer will generate the attention maps\n",
        "            layers.Conv3D(\n",
        "                filters=num_tokens,\n",
        "                kernel_size=(3, 3, 3),\n",
        "                activation=\"sigmoid\",  # Note sigmoid for [0, 1] output\n",
        "                padding=\"same\",\n",
        "                use_bias=False,\n",
        "            ),\n",
        "            # Reshape and Permute\n",
        "            layers.Reshape((-1, num_tokens)),  # (B, T*H*W, num_of_tokens)\n",
        "            layers.Permute((2, 1)),\n",
        "        ]\n",
        "    )(\n",
        "        x\n",
        "    )  # (B, num_of_tokens, T*H*W)\n",
        "\n",
        "    # Reshape the input to align it with the output of the conv block.\n",
        "    num_filters = inputs.shape[-1]\n",
        "    inputs = layers.Reshape((1, -1, num_filters))(inputs)  # inputs == (B, 1, T*H*W, C)\n",
        "\n",
        "    # Element-Wise multiplication of the attention maps and the inputs\n",
        "    attended_inputs = (\n",
        "        attention_maps[..., tf.newaxis] * inputs\n",
        "    )  # (B, num_tokens, T*H*W, C)\n",
        "\n",
        "    # Global average pooling the element wise multiplication result.\n",
        "    outputs = tf.reduce_mean(attended_inputs, axis=2)  # (B, num_tokens, C)\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "iqWF1fga02k_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Block"
      ],
      "metadata": {
        "id": "Sa1TfLGyUYd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp(x, dropout_rate, hidden_units):\n",
        "    # Iterate over the hidden units and add Dense => Dropout.\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def transformer(encoded_patches):\n",
        "    # Layer normalization 1.\n",
        "    x1 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(encoded_patches)\n",
        "\n",
        "    # Multi Head Self Attention layer 1.\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=NUM_HEADS, key_dim=PROJECTION_DIM, dropout=0.1\n",
        "    )(x1, x1)\n",
        "\n",
        "    # Skip connection 1.\n",
        "    x2 = layers.Add()([attention_output, encoded_patches])\n",
        "\n",
        "    # Layer normalization 2.\n",
        "    x3 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x2)\n",
        "\n",
        "    # MLP layer 1.\n",
        "    x4 = mlp(x3, hidden_units=MLP_UNITS, dropout_rate=0.1)\n",
        "\n",
        "    # Skip connection 2.\n",
        "    encoded_patches = layers.Add()([x4, x2])\n",
        "    return encoded_patches"
      ],
      "metadata": {
        "id": "Z_28GhKHUbOh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ViViT model\n"
      ],
      "metadata": {
        "id": "EEIXTFKkUeHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vivit_classifier(\n",
        "    num_tokens,\n",
        "    num_classes,\n",
        "    tubelet_embedder,\n",
        "    positional_encoder,\n",
        "    input_shape=INPUT_SHAPE,\n",
        "    transformer_layers=NUM_LAYERS,\n",
        "    num_heads=NUM_HEADS,\n",
        "    embed_dim=PROJECTION_DIM,\n",
        "    layer_norm_eps=LAYER_NORM_EPS,\n",
        "    use_token_learner=True,\n",
        "):\n",
        "    # Get the input layer\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Create patches.\n",
        "    patches = tubelet_embedder(inputs)  # (B, num_tokens, embed_dim)\n",
        "    # Encode patches.\n",
        "    encoded_patches = positional_encoder(patches)  # (B, num_tokens, embed_dim)\n",
        "\n",
        "    for i in range(transformer_layers):\n",
        "        # Add a Transformer block.\n",
        "        encoded_patches = transformer(encoded_patches)\n",
        "\n",
        "        # Add TokenLearner layer in the middle(1/2) of the architecture. \n",
        "        if use_token_learner and i == transformer_layers // 2:\n",
        "            _, thw, c = encoded_patches.shape\n",
        "            n = int(pow(thw, 1/3))\n",
        "            encoded_patches = layers.Reshape((-1, n, n, n, c))(encoded_patches)  # (B, n, n, n, c)\n",
        "            encoded_patches = token_learner(encoded_patches, num_tokens)  # (B, num_tokens, C)\n",
        "\n",
        "    # Layer normalization and Global average pooling.\n",
        "    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n",
        "    representation = layers.GlobalAvgPool1D()(representation)\n",
        "\n",
        "    # Classify outputs.\n",
        "    outputs = layers.Dense(units=num_classes, activation=\"softmax\")(representation)\n",
        "\n",
        "    # Create Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "tDxfOWlCl2ZE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train\n",
        "\n",
        "### Training Utility"
      ],
      "metadata": {
        "id": "WLXSUWTDUjTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(dataset_info, \n",
        "                   patch_size,\n",
        "                   use_token_learner=True):\n",
        "  \n",
        "    with tf.device(DEVICE_NAME):\n",
        "        # Load dataset\n",
        "        dataset_name, num_classes = dataset_info\n",
        "        trainloader, validloader, testloader = get_dataloaders(dataset_name)\n",
        "        \n",
        "        # Set number of patches\n",
        "        num_patches = (INPUT_SHAPE[0] // patch_size) ** 2\n",
        "\n",
        "        # Initialize model\n",
        "        model = create_vivit_classifier(\n",
        "            num_tokens=num_patches,\n",
        "            num_classes=num_classes,\n",
        "            tubelet_embedder=TubeletEmbedding(\n",
        "                embed_dim=PROJECTION_DIM, patch_size=patch_size\n",
        "            ),\n",
        "            positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n",
        "            use_token_learner=use_token_learner,\n",
        "        )\n",
        "\n",
        "        # Define AdamW optimizer for regularization\n",
        "        optimizer = tfa.optimizers.AdamW(\n",
        "            learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
        "        )\n",
        "        model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=[\n",
        "                keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "                keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "            ],\n",
        "        )\n",
        "\n",
        "        # Define early stop callbacks (for variations of datasets.)\n",
        "        earlystop_callback = keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=15,\n",
        "            start_from_epoch=20\n",
        "        )\n",
        "\n",
        "        # Define reduce learning rate on plateau\n",
        "        reducelr_callback = keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss', factor=0.5,\n",
        "            patience=5, min_lr=1e-6\n",
        "        )\n",
        "\n",
        "        # Define checkpoint callbacks\n",
        "        checkpoint_filepath = \"/tmp/checkpoint\"\n",
        "        checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "            checkpoint_filepath,\n",
        "            monitor=\"val_accuracy\",\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "        )\n",
        "\n",
        "        # Define tensorboard callbacks\n",
        "        log_dir = f\"logs/fit/{dataset_name}/tl:{use_token_learner}/p:{patch_size}/\" \\\n",
        "                  + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "        # Train the model.\n",
        "        _ = model.fit(\n",
        "            trainloader,\n",
        "            epochs=EPOCHS,\n",
        "            validation_data=validloader,\n",
        "            callbacks=[tensorboard_callback, \n",
        "                       checkpoint_callback, \n",
        "                       earlystop_callback,\n",
        "                       reducelr_callback],\n",
        "        )\n",
        "\n",
        "        model.load_weights(checkpoint_filepath)\n",
        "        _, accuracy, top_5_accuracy = model.evaluate(testloader)\n",
        "        print(\"TRAIN RESULT : \")\n",
        "        print(f\"{dataset_name}/tl:{use_token_learner}/p:{patch_size}\")\n",
        "        print(f\"    Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "        print(f\"    Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")"
      ],
      "metadata": {
        "id": "B3xe_Vj1l8fK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear out prior logging data.\n",
        "!rm -rf logs/fit\n",
        "\n",
        "# Train total 2*2*2 = 8 models.\n",
        "for dataset_info in DATASET_INFOS[:2]:\n",
        "    for patch_size in PATCH_SIZES:\n",
        "        run_experiment(dataset_info, patch_size, use_token_learner=False)\n",
        "        run_experiment(dataset_info, patch_size, use_token_learner=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-eeRlenHUO2",
        "outputId": "46373d56-259b-4f19-f18e-0d46669eb092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "16/16 [==============================] - 23s 297ms/step - loss: 2.5600 - accuracy: 0.1132 - top-5-accuracy: 0.5401 - val_loss: 2.4102 - val_accuracy: 0.1553 - val_top-5-accuracy: 0.5342 - lr: 1.0000e-04\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 2s 159ms/step - loss: 2.2658 - accuracy: 0.1523 - top-5-accuracy: 0.6502 - val_loss: 2.2890 - val_accuracy: 0.1553 - val_top-5-accuracy: 0.6584 - lr: 1.0000e-04\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 3s 181ms/step - loss: 2.1571 - accuracy: 0.1934 - top-5-accuracy: 0.7243 - val_loss: 1.9768 - val_accuracy: 0.1739 - val_top-5-accuracy: 0.8137 - lr: 1.0000e-04\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 2.0496 - accuracy: 0.2274 - top-5-accuracy: 0.7757 - val_loss: 1.9218 - val_accuracy: 0.2671 - val_top-5-accuracy: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.9781 - accuracy: 0.2160 - top-5-accuracy: 0.7953 - val_loss: 1.6392 - val_accuracy: 0.3416 - val_top-5-accuracy: 0.8509 - lr: 1.0000e-04\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.8513 - accuracy: 0.2870 - top-5-accuracy: 0.8251 - val_loss: 1.5624 - val_accuracy: 0.3540 - val_top-5-accuracy: 0.8758 - lr: 1.0000e-04\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.6756 - accuracy: 0.3498 - top-5-accuracy: 0.8776 - val_loss: 1.2869 - val_accuracy: 0.5031 - val_top-5-accuracy: 0.9627 - lr: 1.0000e-04\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 2s 156ms/step - loss: 1.6105 - accuracy: 0.3477 - top-5-accuracy: 0.8992 - val_loss: 1.2354 - val_accuracy: 0.4783 - val_top-5-accuracy: 0.9565 - lr: 1.0000e-04\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 1.5126 - accuracy: 0.4043 - top-5-accuracy: 0.9064 - val_loss: 1.3690 - val_accuracy: 0.4348 - val_top-5-accuracy: 0.9503 - lr: 1.0000e-04\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 1.4557 - accuracy: 0.4033 - top-5-accuracy: 0.9270 - val_loss: 1.1592 - val_accuracy: 0.5031 - val_top-5-accuracy: 0.9503 - lr: 1.0000e-04\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.3361 - accuracy: 0.4578 - top-5-accuracy: 0.9414 - val_loss: 1.0580 - val_accuracy: 0.5093 - val_top-5-accuracy: 0.9565 - lr: 1.0000e-04\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.2537 - accuracy: 0.5103 - top-5-accuracy: 0.9475 - val_loss: 0.9494 - val_accuracy: 0.6149 - val_top-5-accuracy: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 2s 155ms/step - loss: 1.1734 - accuracy: 0.5504 - top-5-accuracy: 0.9486 - val_loss: 0.9895 - val_accuracy: 0.5963 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 1.1781 - accuracy: 0.5453 - top-5-accuracy: 0.9527 - val_loss: 0.9024 - val_accuracy: 0.6398 - val_top-5-accuracy: 0.9689 - lr: 1.0000e-04\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0604 - accuracy: 0.5926 - top-5-accuracy: 0.9619 - val_loss: 0.7399 - val_accuracy: 0.7143 - val_top-5-accuracy: 0.9752 - lr: 1.0000e-04\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0107 - accuracy: 0.6039 - top-5-accuracy: 0.9702 - val_loss: 0.8356 - val_accuracy: 0.6832 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 1.0081 - accuracy: 0.6193 - top-5-accuracy: 0.9671 - val_loss: 0.8929 - val_accuracy: 0.6335 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 0.9255 - accuracy: 0.6461 - top-5-accuracy: 0.9753 - val_loss: 0.6718 - val_accuracy: 0.7640 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 2s 152ms/step - loss: 0.8992 - accuracy: 0.6615 - top-5-accuracy: 0.9815 - val_loss: 0.8560 - val_accuracy: 0.6770 - val_top-5-accuracy: 0.9752 - lr: 1.0000e-04\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 2s 153ms/step - loss: 0.7508 - accuracy: 0.7253 - top-5-accuracy: 0.9887 - val_loss: 0.7124 - val_accuracy: 0.7516 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 2s 151ms/step - loss: 0.6980 - accuracy: 0.7356 - top-5-accuracy: 0.9907 - val_loss: 0.7659 - val_accuracy: 0.7578 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 2s 152ms/step - loss: 0.6492 - accuracy: 0.7613 - top-5-accuracy: 0.9918 - val_loss: 1.1462 - val_accuracy: 0.6087 - val_top-5-accuracy: 0.9627 - lr: 1.0000e-04\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.7601 - accuracy: 0.7243 - top-5-accuracy: 0.9846 - val_loss: 0.6312 - val_accuracy: 0.8012 - val_top-5-accuracy: 0.9752 - lr: 1.0000e-04\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.5832 - accuracy: 0.7932 - top-5-accuracy: 0.9907 - val_loss: 0.5479 - val_accuracy: 0.8323 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 2s 151ms/step - loss: 0.5292 - accuracy: 0.8128 - top-5-accuracy: 0.9918 - val_loss: 0.6391 - val_accuracy: 0.7950 - val_top-5-accuracy: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 2s 151ms/step - loss: 0.5940 - accuracy: 0.7922 - top-5-accuracy: 0.9959 - val_loss: 0.6410 - val_accuracy: 0.7764 - val_top-5-accuracy: 0.9752 - lr: 1.0000e-04\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 2s 153ms/step - loss: 0.5680 - accuracy: 0.7840 - top-5-accuracy: 0.9918 - val_loss: 0.6319 - val_accuracy: 0.8199 - val_top-5-accuracy: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.4708 - accuracy: 0.8344 - top-5-accuracy: 0.9949 - val_loss: 0.6670 - val_accuracy: 0.8385 - val_top-5-accuracy: 0.9938 - lr: 1.0000e-04\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 2s 153ms/step - loss: 0.3774 - accuracy: 0.8735 - top-5-accuracy: 0.9979 - val_loss: 0.6323 - val_accuracy: 0.8323 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 3s 180ms/step - loss: 0.3584 - accuracy: 0.8765 - top-5-accuracy: 0.9979 - val_loss: 0.4960 - val_accuracy: 0.8696 - val_top-5-accuracy: 0.9876 - lr: 3.0000e-05\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.2895 - accuracy: 0.8899 - top-5-accuracy: 0.9990 - val_loss: 0.5031 - val_accuracy: 0.8882 - val_top-5-accuracy: 0.9752 - lr: 3.0000e-05\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.2582 - accuracy: 0.9218 - top-5-accuracy: 0.9969 - val_loss: 0.4777 - val_accuracy: 0.8944 - val_top-5-accuracy: 0.9814 - lr: 3.0000e-05\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.2405 - accuracy: 0.9270 - top-5-accuracy: 0.9979 - val_loss: 0.4874 - val_accuracy: 0.9193 - val_top-5-accuracy: 0.9689 - lr: 3.0000e-05\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.2149 - accuracy: 0.9362 - top-5-accuracy: 0.9979 - val_loss: 0.4763 - val_accuracy: 0.9255 - val_top-5-accuracy: 0.9689 - lr: 3.0000e-05\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 2s 153ms/step - loss: 0.1892 - accuracy: 0.9414 - top-5-accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.9193 - val_top-5-accuracy: 0.9752 - lr: 3.0000e-05\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.1725 - accuracy: 0.9516 - top-5-accuracy: 0.9990 - val_loss: 0.4459 - val_accuracy: 0.9255 - val_top-5-accuracy: 0.9814 - lr: 3.0000e-05\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.1564 - accuracy: 0.9588 - top-5-accuracy: 1.0000 - val_loss: 0.5000 - val_accuracy: 0.9130 - val_top-5-accuracy: 0.9752 - lr: 3.0000e-05\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.1611 - accuracy: 0.9496 - top-5-accuracy: 1.0000 - val_loss: 0.5217 - val_accuracy: 0.9130 - val_top-5-accuracy: 0.9752 - lr: 3.0000e-05\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.1412 - accuracy: 0.9640 - top-5-accuracy: 1.0000 - val_loss: 0.5554 - val_accuracy: 0.8944 - val_top-5-accuracy: 0.9814 - lr: 3.0000e-05\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.1275 - accuracy: 0.9671 - top-5-accuracy: 1.0000 - val_loss: 0.5600 - val_accuracy: 0.8944 - val_top-5-accuracy: 0.9752 - lr: 3.0000e-05\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.1155 - accuracy: 0.9681 - top-5-accuracy: 1.0000 - val_loss: 0.5404 - val_accuracy: 0.8882 - val_top-5-accuracy: 0.9752 - lr: 3.0000e-05\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 2s 148ms/step - loss: 0.0937 - accuracy: 0.9763 - top-5-accuracy: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.9068 - val_top-5-accuracy: 0.9752 - lr: 9.0000e-06\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.0852 - accuracy: 0.9794 - top-5-accuracy: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.9068 - val_top-5-accuracy: 0.9814 - lr: 9.0000e-06\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 2s 153ms/step - loss: 0.0808 - accuracy: 0.9825 - top-5-accuracy: 1.0000 - val_loss: 0.5135 - val_accuracy: 0.9068 - val_top-5-accuracy: 0.9814 - lr: 9.0000e-06\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.0752 - accuracy: 0.9846 - top-5-accuracy: 1.0000 - val_loss: 0.5271 - val_accuracy: 0.9068 - val_top-5-accuracy: 0.9814 - lr: 9.0000e-06\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 2s 148ms/step - loss: 0.0715 - accuracy: 0.9846 - top-5-accuracy: 1.0000 - val_loss: 0.5158 - val_accuracy: 0.9255 - val_top-5-accuracy: 0.9814 - lr: 9.0000e-06\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.0672 - accuracy: 0.9897 - top-5-accuracy: 1.0000 - val_loss: 0.5230 - val_accuracy: 0.9255 - val_top-5-accuracy: 0.9814 - lr: 2.7000e-06\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 3s 176ms/step - loss: 0.0661 - accuracy: 0.9887 - top-5-accuracy: 1.0000 - val_loss: 0.5203 - val_accuracy: 0.9255 - val_top-5-accuracy: 0.9814 - lr: 2.7000e-06\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 2s 157ms/step - loss: 0.0624 - accuracy: 0.9918 - top-5-accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 0.9255 - val_top-5-accuracy: 0.9814 - lr: 2.7000e-06\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 2s 152ms/step - loss: 0.0597 - accuracy: 0.9897 - top-5-accuracy: 1.0000 - val_loss: 0.5201 - val_accuracy: 0.9255 - val_top-5-accuracy: 0.9814 - lr: 2.7000e-06\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 2s 148ms/step - loss: 0.0617 - accuracy: 0.9907 - top-5-accuracy: 1.0000 - val_loss: 0.5183 - val_accuracy: 0.9255 - val_top-5-accuracy: 0.9814 - lr: 2.7000e-06\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 1.0441 - accuracy: 0.7148 - top-5-accuracy: 0.9738\n",
            "TRAIN RESULT : \n",
            "organmnist3d/tl:False/p:8\n",
            "    Test accuracy: 71.48%\n",
            "    Test top 5 accuracy: 97.38%\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 15s 275ms/step - loss: 2.8391 - accuracy: 0.1060 - top-5-accuracy: 0.5401 - val_loss: 2.4525 - val_accuracy: 0.0621 - val_top-5-accuracy: 0.4907 - lr: 1.0000e-04\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 2.3579 - accuracy: 0.1337 - top-5-accuracy: 0.5494 - val_loss: 2.3919 - val_accuracy: 0.0870 - val_top-5-accuracy: 0.6211 - lr: 1.0000e-04\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 2.2921 - accuracy: 0.1235 - top-5-accuracy: 0.6605 - val_loss: 2.3314 - val_accuracy: 0.0994 - val_top-5-accuracy: 0.6087 - lr: 1.0000e-04\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 2.2343 - accuracy: 0.1677 - top-5-accuracy: 0.6667 - val_loss: 2.1438 - val_accuracy: 0.1801 - val_top-5-accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 2.1273 - accuracy: 0.1749 - top-5-accuracy: 0.7366 - val_loss: 1.9169 - val_accuracy: 0.2298 - val_top-5-accuracy: 0.7888 - lr: 1.0000e-04\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 2s 155ms/step - loss: 2.0715 - accuracy: 0.1770 - top-5-accuracy: 0.7757 - val_loss: 1.9186 - val_accuracy: 0.2236 - val_top-5-accuracy: 0.8137 - lr: 1.0000e-04\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 2.0036 - accuracy: 0.2099 - top-5-accuracy: 0.7798 - val_loss: 1.7675 - val_accuracy: 0.2733 - val_top-5-accuracy: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.9074 - accuracy: 0.2675 - top-5-accuracy: 0.8220 - val_loss: 1.6694 - val_accuracy: 0.2981 - val_top-5-accuracy: 0.8758 - lr: 1.0000e-04\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.8538 - accuracy: 0.2675 - top-5-accuracy: 0.8323 - val_loss: 1.5455 - val_accuracy: 0.3789 - val_top-5-accuracy: 0.8820 - lr: 1.0000e-04\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 2s 154ms/step - loss: 1.7889 - accuracy: 0.2922 - top-5-accuracy: 0.8457 - val_loss: 1.5547 - val_accuracy: 0.3292 - val_top-5-accuracy: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 1.7040 - accuracy: 0.3282 - top-5-accuracy: 0.8714 - val_loss: 1.4227 - val_accuracy: 0.3540 - val_top-5-accuracy: 0.9379 - lr: 1.0000e-04\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.5854 - accuracy: 0.3580 - top-5-accuracy: 0.9002 - val_loss: 1.3016 - val_accuracy: 0.4907 - val_top-5-accuracy: 0.9317 - lr: 1.0000e-04\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 2s 157ms/step - loss: 1.5171 - accuracy: 0.3909 - top-5-accuracy: 0.9136 - val_loss: 1.3663 - val_accuracy: 0.3851 - val_top-5-accuracy: 0.9379 - lr: 1.0000e-04\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 2s 151ms/step - loss: 1.4944 - accuracy: 0.4208 - top-5-accuracy: 0.9167 - val_loss: 1.2181 - val_accuracy: 0.4783 - val_top-5-accuracy: 0.9503 - lr: 1.0000e-04\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.3825 - accuracy: 0.4599 - top-5-accuracy: 0.9311 - val_loss: 1.3135 - val_accuracy: 0.5155 - val_top-5-accuracy: 0.9441 - lr: 1.0000e-04\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3221 - accuracy: 0.4640 - top-5-accuracy: 0.9383 - val_loss: 1.0231 - val_accuracy: 0.5901 - val_top-5-accuracy: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 2s 158ms/step - loss: 1.2565 - accuracy: 0.5051 - top-5-accuracy: 0.9558 - val_loss: 1.1456 - val_accuracy: 0.5776 - val_top-5-accuracy: 0.9441 - lr: 1.0000e-04\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.2331 - accuracy: 0.5309 - top-5-accuracy: 0.9444 - val_loss: 1.0211 - val_accuracy: 0.6211 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 1.2144 - accuracy: 0.5237 - top-5-accuracy: 0.9547 - val_loss: 1.0366 - val_accuracy: 0.5342 - val_top-5-accuracy: 0.9752 - lr: 1.0000e-04\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1580 - accuracy: 0.5422 - top-5-accuracy: 0.9547 - val_loss: 0.8580 - val_accuracy: 0.6460 - val_top-5-accuracy: 0.9938 - lr: 1.0000e-04\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 2s 157ms/step - loss: 1.0361 - accuracy: 0.6029 - top-5-accuracy: 0.9588 - val_loss: 0.8853 - val_accuracy: 0.6335 - val_top-5-accuracy: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 1.1324 - accuracy: 0.5710 - top-5-accuracy: 0.9516 - val_loss: 0.8996 - val_accuracy: 0.6398 - val_top-5-accuracy: 0.9938 - lr: 1.0000e-04\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9222 - accuracy: 0.6584 - top-5-accuracy: 0.9743 - val_loss: 0.8071 - val_accuracy: 0.6770 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8514 - accuracy: 0.6780 - top-5-accuracy: 0.9774 - val_loss: 0.8821 - val_accuracy: 0.7205 - val_top-5-accuracy: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.8369 - accuracy: 0.6883 - top-5-accuracy: 0.9671 - val_loss: 0.7837 - val_accuracy: 0.7516 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.6984 - accuracy: 0.7315 - top-5-accuracy: 0.9805 - val_loss: 0.6340 - val_accuracy: 0.7826 - val_top-5-accuracy: 0.9938 - lr: 1.0000e-04\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.6637 - accuracy: 0.7603 - top-5-accuracy: 0.9825 - val_loss: 0.5417 - val_accuracy: 0.8137 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.5987 - accuracy: 0.7829 - top-5-accuracy: 0.9897 - val_loss: 0.6048 - val_accuracy: 0.8261 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 2s 154ms/step - loss: 0.5261 - accuracy: 0.7994 - top-5-accuracy: 0.9877 - val_loss: 0.5825 - val_accuracy: 0.8137 - val_top-5-accuracy: 0.9938 - lr: 1.0000e-04\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.5271 - accuracy: 0.7942 - top-5-accuracy: 0.9907 - val_loss: 0.7109 - val_accuracy: 0.7888 - val_top-5-accuracy: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.5041 - accuracy: 0.8282 - top-5-accuracy: 0.9928 - val_loss: 0.6544 - val_accuracy: 0.8323 - val_top-5-accuracy: 0.9689 - lr: 1.0000e-04\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 2s 158ms/step - loss: 0.4788 - accuracy: 0.8251 - top-5-accuracy: 0.9928 - val_loss: 0.7434 - val_accuracy: 0.7702 - val_top-5-accuracy: 0.9938 - lr: 1.0000e-04\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.3930 - accuracy: 0.8580 - top-5-accuracy: 0.9907 - val_loss: 0.4597 - val_accuracy: 0.8634 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.3007 - accuracy: 0.8920 - top-5-accuracy: 0.9969 - val_loss: 0.4251 - val_accuracy: 0.8758 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 2s 154ms/step - loss: 0.2533 - accuracy: 0.9084 - top-5-accuracy: 0.9969 - val_loss: 0.4173 - val_accuracy: 0.8758 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.2289 - accuracy: 0.9187 - top-5-accuracy: 0.9969 - val_loss: 0.5349 - val_accuracy: 0.8447 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.2159 - accuracy: 0.9321 - top-5-accuracy: 0.9979 - val_loss: 0.4588 - val_accuracy: 0.8696 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.2159 - accuracy: 0.9280 - top-5-accuracy: 0.9990 - val_loss: 0.4086 - val_accuracy: 0.9006 - val_top-5-accuracy: 0.9938 - lr: 3.0000e-05\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 2s 155ms/step - loss: 0.2185 - accuracy: 0.9270 - top-5-accuracy: 0.9990 - val_loss: 0.4523 - val_accuracy: 0.8696 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.1784 - accuracy: 0.9393 - top-5-accuracy: 0.9990 - val_loss: 0.4236 - val_accuracy: 0.8758 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.1625 - accuracy: 0.9547 - top-5-accuracy: 0.9990 - val_loss: 0.5113 - val_accuracy: 0.8696 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 2s 159ms/step - loss: 0.1484 - accuracy: 0.9516 - top-5-accuracy: 0.9990 - val_loss: 0.4956 - val_accuracy: 0.8882 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 2s 155ms/step - loss: 0.1450 - accuracy: 0.9568 - top-5-accuracy: 0.9990 - val_loss: 0.5837 - val_accuracy: 0.8509 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 2s 148ms/step - loss: 0.1304 - accuracy: 0.9599 - top-5-accuracy: 0.9990 - val_loss: 0.3917 - val_accuracy: 0.9006 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 2s 156ms/step - loss: 0.0952 - accuracy: 0.9712 - top-5-accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.8758 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 2s 154ms/step - loss: 0.0939 - accuracy: 0.9733 - top-5-accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.8882 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 2s 153ms/step - loss: 0.0844 - accuracy: 0.9794 - top-5-accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.8882 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 2s 148ms/step - loss: 0.0801 - accuracy: 0.9805 - top-5-accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.8758 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 2s 149ms/step - loss: 0.0759 - accuracy: 0.9815 - top-5-accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.8820 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.0721 - accuracy: 0.9815 - top-5-accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.8758 - val_top-5-accuracy: 1.0000 - lr: 2.7000e-06\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 2s 156ms/step - loss: 0.0644 - accuracy: 0.9856 - top-5-accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.8820 - val_top-5-accuracy: 1.0000 - lr: 2.7000e-06\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 2s 154ms/step - loss: 0.0669 - accuracy: 0.9897 - top-5-accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.8882 - val_top-5-accuracy: 0.9938 - lr: 2.7000e-06\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 2s 154ms/step - loss: 0.0646 - accuracy: 0.9897 - top-5-accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.8882 - val_top-5-accuracy: 1.0000 - lr: 2.7000e-06\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.0679 - accuracy: 0.9856 - top-5-accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.8944 - val_top-5-accuracy: 1.0000 - lr: 2.7000e-06\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 2s 153ms/step - loss: 0.0648 - accuracy: 0.9856 - top-5-accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.8944 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 2s 154ms/step - loss: 0.0632 - accuracy: 0.9887 - top-5-accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.8820 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 3s 178ms/step - loss: 0.0627 - accuracy: 0.9897 - top-5-accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.8944 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.0616 - accuracy: 0.9907 - top-5-accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.8944 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 2s 152ms/step - loss: 0.0610 - accuracy: 0.9907 - top-5-accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.8944 - val_top-5-accuracy: 0.9938 - lr: 1.0000e-06\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 1.3542 - accuracy: 0.6672 - top-5-accuracy: 0.9508\n",
            "TRAIN RESULT : \n",
            "organmnist3d/tl:True/p:8\n",
            "    Test accuracy: 66.72%\n",
            "    Test top 5 accuracy: 95.08%\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 14s 249ms/step - loss: 2.4860 - accuracy: 0.1440 - top-5-accuracy: 0.5988 - val_loss: 2.1371 - val_accuracy: 0.3789 - val_top-5-accuracy: 0.7950 - lr: 1.0000e-04\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 2.1341 - accuracy: 0.2479 - top-5-accuracy: 0.7335 - val_loss: 1.9823 - val_accuracy: 0.3292 - val_top-5-accuracy: 0.7516 - lr: 1.0000e-04\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 1.9230 - accuracy: 0.3364 - top-5-accuracy: 0.7891 - val_loss: 1.6059 - val_accuracy: 0.3727 - val_top-5-accuracy: 0.9130 - lr: 1.0000e-04\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.6876 - accuracy: 0.3868 - top-5-accuracy: 0.8673 - val_loss: 1.2603 - val_accuracy: 0.4969 - val_top-5-accuracy: 0.9627 - lr: 1.0000e-04\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 1.5710 - accuracy: 0.4342 - top-5-accuracy: 0.8961 - val_loss: 1.1002 - val_accuracy: 0.5901 - val_top-5-accuracy: 0.9503 - lr: 1.0000e-04\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 1.4269 - accuracy: 0.4805 - top-5-accuracy: 0.9167 - val_loss: 1.1066 - val_accuracy: 0.6273 - val_top-5-accuracy: 0.9379 - lr: 1.0000e-04\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 1.3478 - accuracy: 0.5257 - top-5-accuracy: 0.9187 - val_loss: 0.9906 - val_accuracy: 0.6832 - val_top-5-accuracy: 0.9503 - lr: 1.0000e-04\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 3s 177ms/step - loss: 1.2116 - accuracy: 0.5792 - top-5-accuracy: 0.9290 - val_loss: 0.7554 - val_accuracy: 0.7702 - val_top-5-accuracy: 0.9689 - lr: 1.0000e-04\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 1.0707 - accuracy: 0.6080 - top-5-accuracy: 0.9547 - val_loss: 0.7529 - val_accuracy: 0.7578 - val_top-5-accuracy: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 2s 129ms/step - loss: 1.0713 - accuracy: 0.5998 - top-5-accuracy: 0.9537 - val_loss: 0.8934 - val_accuracy: 0.6522 - val_top-5-accuracy: 0.9565 - lr: 1.0000e-04\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 1.0155 - accuracy: 0.6379 - top-5-accuracy: 0.9547 - val_loss: 0.7626 - val_accuracy: 0.7764 - val_top-5-accuracy: 0.9627 - lr: 1.0000e-04\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.9572 - accuracy: 0.6523 - top-5-accuracy: 0.9578 - val_loss: 0.5986 - val_accuracy: 0.8199 - val_top-5-accuracy: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 2s 129ms/step - loss: 0.9308 - accuracy: 0.6656 - top-5-accuracy: 0.9630 - val_loss: 0.7166 - val_accuracy: 0.7826 - val_top-5-accuracy: 0.9627 - lr: 1.0000e-04\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.8866 - accuracy: 0.6852 - top-5-accuracy: 0.9681 - val_loss: 0.6578 - val_accuracy: 0.8012 - val_top-5-accuracy: 0.9752 - lr: 1.0000e-04\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.8824 - accuracy: 0.6739 - top-5-accuracy: 0.9578 - val_loss: 0.4945 - val_accuracy: 0.8323 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.8487 - accuracy: 0.6934 - top-5-accuracy: 0.9743 - val_loss: 0.4809 - val_accuracy: 0.8634 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.8819 - accuracy: 0.6800 - top-5-accuracy: 0.9660 - val_loss: 0.4916 - val_accuracy: 0.8447 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.7993 - accuracy: 0.7160 - top-5-accuracy: 0.9753 - val_loss: 0.4619 - val_accuracy: 0.8571 - val_top-5-accuracy: 0.9938 - lr: 1.0000e-04\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 2s 129ms/step - loss: 0.7684 - accuracy: 0.7284 - top-5-accuracy: 0.9650 - val_loss: 0.4620 - val_accuracy: 0.8323 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.7359 - accuracy: 0.7366 - top-5-accuracy: 0.9794 - val_loss: 0.5901 - val_accuracy: 0.8261 - val_top-5-accuracy: 0.9689 - lr: 1.0000e-04\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 2s 131ms/step - loss: 0.7609 - accuracy: 0.7243 - top-5-accuracy: 0.9784 - val_loss: 0.4987 - val_accuracy: 0.8323 - val_top-5-accuracy: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 2s 162ms/step - loss: 0.6872 - accuracy: 0.7603 - top-5-accuracy: 0.9835 - val_loss: 0.4388 - val_accuracy: 0.8758 - val_top-5-accuracy: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 2s 132ms/step - loss: 0.6350 - accuracy: 0.7654 - top-5-accuracy: 0.9856 - val_loss: 0.5111 - val_accuracy: 0.8323 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.6248 - accuracy: 0.7716 - top-5-accuracy: 0.9825 - val_loss: 0.5552 - val_accuracy: 0.8075 - val_top-5-accuracy: 0.9689 - lr: 1.0000e-04\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.6130 - accuracy: 0.7881 - top-5-accuracy: 0.9846 - val_loss: 0.4336 - val_accuracy: 0.8571 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.5823 - accuracy: 0.7870 - top-5-accuracy: 0.9897 - val_loss: 0.5133 - val_accuracy: 0.8137 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.5688 - accuracy: 0.7922 - top-5-accuracy: 0.9897 - val_loss: 0.5300 - val_accuracy: 0.8261 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.5936 - accuracy: 0.8045 - top-5-accuracy: 0.9877 - val_loss: 0.4715 - val_accuracy: 0.8385 - val_top-5-accuracy: 0.9752 - lr: 1.0000e-04\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.5606 - accuracy: 0.7891 - top-5-accuracy: 0.9938 - val_loss: 0.4631 - val_accuracy: 0.8509 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.5470 - accuracy: 0.8056 - top-5-accuracy: 0.9897 - val_loss: 0.7355 - val_accuracy: 0.7205 - val_top-5-accuracy: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.4953 - accuracy: 0.8241 - top-5-accuracy: 0.9928 - val_loss: 0.3794 - val_accuracy: 0.8758 - val_top-5-accuracy: 0.9938 - lr: 3.0000e-05\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3922 - accuracy: 0.8601 - top-5-accuracy: 0.9949 - val_loss: 0.3445 - val_accuracy: 0.8882 - val_top-5-accuracy: 0.9876 - lr: 3.0000e-05\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.3847 - accuracy: 0.8591 - top-5-accuracy: 0.9969 - val_loss: 0.3651 - val_accuracy: 0.8758 - val_top-5-accuracy: 0.9814 - lr: 3.0000e-05\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.3275 - accuracy: 0.8837 - top-5-accuracy: 0.9949 - val_loss: 0.4431 - val_accuracy: 0.8447 - val_top-5-accuracy: 0.9938 - lr: 3.0000e-05\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.3684 - accuracy: 0.8735 - top-5-accuracy: 0.9949 - val_loss: 0.3184 - val_accuracy: 0.8882 - val_top-5-accuracy: 0.9938 - lr: 3.0000e-05\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.3256 - accuracy: 0.8848 - top-5-accuracy: 0.9949 - val_loss: 0.3534 - val_accuracy: 0.8634 - val_top-5-accuracy: 0.9876 - lr: 3.0000e-05\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.2828 - accuracy: 0.9105 - top-5-accuracy: 0.9969 - val_loss: 0.3442 - val_accuracy: 0.8758 - val_top-5-accuracy: 0.9938 - lr: 3.0000e-05\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.2890 - accuracy: 0.9084 - top-5-accuracy: 0.9949 - val_loss: 0.4519 - val_accuracy: 0.8696 - val_top-5-accuracy: 0.9814 - lr: 3.0000e-05\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 2s 162ms/step - loss: 0.2840 - accuracy: 0.9064 - top-5-accuracy: 0.9959 - val_loss: 0.4047 - val_accuracy: 0.8944 - val_top-5-accuracy: 0.9814 - lr: 3.0000e-05\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.2520 - accuracy: 0.9146 - top-5-accuracy: 0.9959 - val_loss: 0.3719 - val_accuracy: 0.8944 - val_top-5-accuracy: 0.9938 - lr: 3.0000e-05\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.2584 - accuracy: 0.9095 - top-5-accuracy: 0.9969 - val_loss: 0.3736 - val_accuracy: 0.8820 - val_top-5-accuracy: 0.9876 - lr: 9.0000e-06\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.2452 - accuracy: 0.9208 - top-5-accuracy: 0.9990 - val_loss: 0.3512 - val_accuracy: 0.8820 - val_top-5-accuracy: 0.9938 - lr: 9.0000e-06\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.2268 - accuracy: 0.9321 - top-5-accuracy: 0.9990 - val_loss: 0.3243 - val_accuracy: 0.8820 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 2s 163ms/step - loss: 0.2251 - accuracy: 0.9187 - top-5-accuracy: 0.9969 - val_loss: 0.3055 - val_accuracy: 0.9068 - val_top-5-accuracy: 0.9938 - lr: 9.0000e-06\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.2198 - accuracy: 0.9290 - top-5-accuracy: 0.9979 - val_loss: 0.3765 - val_accuracy: 0.8882 - val_top-5-accuracy: 0.9938 - lr: 9.0000e-06\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.2257 - accuracy: 0.9239 - top-5-accuracy: 0.9990 - val_loss: 0.3474 - val_accuracy: 0.8882 - val_top-5-accuracy: 0.9938 - lr: 9.0000e-06\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 2s 129ms/step - loss: 0.2203 - accuracy: 0.9259 - top-5-accuracy: 0.9990 - val_loss: 0.3487 - val_accuracy: 0.8882 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 2s 129ms/step - loss: 0.2014 - accuracy: 0.9321 - top-5-accuracy: 0.9990 - val_loss: 0.3827 - val_accuracy: 0.8820 - val_top-5-accuracy: 0.9938 - lr: 9.0000e-06\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 2s 129ms/step - loss: 0.2005 - accuracy: 0.9393 - top-5-accuracy: 0.9990 - val_loss: 0.3506 - val_accuracy: 0.8820 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 2s 130ms/step - loss: 0.2005 - accuracy: 0.9311 - top-5-accuracy: 0.9979 - val_loss: 0.3342 - val_accuracy: 0.9006 - val_top-5-accuracy: 1.0000 - lr: 2.7000e-06\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.1838 - accuracy: 0.9414 - top-5-accuracy: 0.9990 - val_loss: 0.3300 - val_accuracy: 0.8944 - val_top-5-accuracy: 1.0000 - lr: 2.7000e-06\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.1897 - accuracy: 0.9403 - top-5-accuracy: 0.9979 - val_loss: 0.3074 - val_accuracy: 0.9130 - val_top-5-accuracy: 1.0000 - lr: 2.7000e-06\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 2s 131ms/step - loss: 0.1897 - accuracy: 0.9372 - top-5-accuracy: 0.9990 - val_loss: 0.3450 - val_accuracy: 0.8820 - val_top-5-accuracy: 0.9938 - lr: 2.7000e-06\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.1757 - accuracy: 0.9527 - top-5-accuracy: 0.9969 - val_loss: 0.3465 - val_accuracy: 0.8820 - val_top-5-accuracy: 0.9938 - lr: 2.7000e-06\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 2s 129ms/step - loss: 0.1844 - accuracy: 0.9403 - top-5-accuracy: 0.9979 - val_loss: 0.3291 - val_accuracy: 0.9006 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.1885 - accuracy: 0.9362 - top-5-accuracy: 0.9979 - val_loss: 0.3343 - val_accuracy: 0.8944 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.1795 - accuracy: 0.9414 - top-5-accuracy: 0.9979 - val_loss: 0.3276 - val_accuracy: 0.8944 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.1731 - accuracy: 0.9434 - top-5-accuracy: 0.9990 - val_loss: 0.3206 - val_accuracy: 0.9068 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.1798 - accuracy: 0.9475 - top-5-accuracy: 0.9979 - val_loss: 0.3231 - val_accuracy: 0.9068 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-06\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.4444 - accuracy: 0.6590 - top-5-accuracy: 0.9328\n",
            "TRAIN RESULT : \n",
            "organmnist3d/tl:False/p:16\n",
            "    Test accuracy: 65.9%\n",
            "    Test top 5 accuracy: 93.28%\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 15s 263ms/step - loss: 2.6296 - accuracy: 0.1091 - top-5-accuracy: 0.5401 - val_loss: 2.4185 - val_accuracy: 0.1739 - val_top-5-accuracy: 0.5404 - lr: 1.0000e-04\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 2.2920 - accuracy: 0.1646 - top-5-accuracy: 0.6276 - val_loss: 2.2402 - val_accuracy: 0.2174 - val_top-5-accuracy: 0.6149 - lr: 1.0000e-04\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 2.1589 - accuracy: 0.2171 - top-5-accuracy: 0.7274 - val_loss: 2.0567 - val_accuracy: 0.3043 - val_top-5-accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 3s 172ms/step - loss: 2.0215 - accuracy: 0.2757 - top-5-accuracy: 0.7716 - val_loss: 1.7523 - val_accuracy: 0.4037 - val_top-5-accuracy: 0.8199 - lr: 1.0000e-04\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 3s 180ms/step - loss: 1.8757 - accuracy: 0.3272 - top-5-accuracy: 0.8117 - val_loss: 1.5450 - val_accuracy: 0.4286 - val_top-5-accuracy: 0.9255 - lr: 1.0000e-04\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 1.6563 - accuracy: 0.4115 - top-5-accuracy: 0.8693 - val_loss: 1.4972 - val_accuracy: 0.3789 - val_top-5-accuracy: 0.8882 - lr: 1.0000e-04\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.5318 - accuracy: 0.4228 - top-5-accuracy: 0.9012 - val_loss: 1.3459 - val_accuracy: 0.4410 - val_top-5-accuracy: 0.9441 - lr: 1.0000e-04\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 3s 177ms/step - loss: 1.4936 - accuracy: 0.4352 - top-5-accuracy: 0.9064 - val_loss: 1.0170 - val_accuracy: 0.6646 - val_top-5-accuracy: 0.9627 - lr: 1.0000e-04\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 1.3076 - accuracy: 0.5175 - top-5-accuracy: 0.9372 - val_loss: 0.9186 - val_accuracy: 0.6335 - val_top-5-accuracy: 0.9689 - lr: 1.0000e-04\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.2434 - accuracy: 0.5319 - top-5-accuracy: 0.9352 - val_loss: 0.6646 - val_accuracy: 0.8012 - val_top-5-accuracy: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 1.0914 - accuracy: 0.6039 - top-5-accuracy: 0.9506 - val_loss: 0.7205 - val_accuracy: 0.7888 - val_top-5-accuracy: 0.9689 - lr: 1.0000e-04\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 3s 175ms/step - loss: 1.0042 - accuracy: 0.6451 - top-5-accuracy: 0.9486 - val_loss: 0.6134 - val_accuracy: 0.8137 - val_top-5-accuracy: 0.9752 - lr: 1.0000e-04\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.9630 - accuracy: 0.6595 - top-5-accuracy: 0.9547 - val_loss: 0.6455 - val_accuracy: 0.7516 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.9657 - accuracy: 0.6533 - top-5-accuracy: 0.9558 - val_loss: 0.8953 - val_accuracy: 0.6957 - val_top-5-accuracy: 0.9627 - lr: 1.0000e-04\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.9799 - accuracy: 0.6307 - top-5-accuracy: 0.9609 - val_loss: 0.7112 - val_accuracy: 0.7764 - val_top-5-accuracy: 0.9689 - lr: 1.0000e-04\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.9441 - accuracy: 0.6646 - top-5-accuracy: 0.9619 - val_loss: 0.6745 - val_accuracy: 0.7764 - val_top-5-accuracy: 0.9752 - lr: 1.0000e-04\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 3s 176ms/step - loss: 0.9484 - accuracy: 0.6595 - top-5-accuracy: 0.9599 - val_loss: 0.5963 - val_accuracy: 0.8199 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.8851 - accuracy: 0.6862 - top-5-accuracy: 0.9712 - val_loss: 0.6028 - val_accuracy: 0.7826 - val_top-5-accuracy: 0.9938 - lr: 1.0000e-04\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 3s 174ms/step - loss: 0.8816 - accuracy: 0.6852 - top-5-accuracy: 0.9671 - val_loss: 0.5430 - val_accuracy: 0.8447 - val_top-5-accuracy: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.7585 - accuracy: 0.7294 - top-5-accuracy: 0.9743 - val_loss: 0.5291 - val_accuracy: 0.8137 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.8146 - accuracy: 0.6811 - top-5-accuracy: 0.9743 - val_loss: 0.7445 - val_accuracy: 0.7329 - val_top-5-accuracy: 0.9752 - lr: 1.0000e-04\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.7562 - accuracy: 0.7109 - top-5-accuracy: 0.9774 - val_loss: 0.5400 - val_accuracy: 0.8137 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.7246 - accuracy: 0.7284 - top-5-accuracy: 0.9794 - val_loss: 0.5301 - val_accuracy: 0.7888 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.7108 - accuracy: 0.7377 - top-5-accuracy: 0.9753 - val_loss: 0.5488 - val_accuracy: 0.8323 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.7934 - accuracy: 0.7150 - top-5-accuracy: 0.9805 - val_loss: 0.4812 - val_accuracy: 0.8323 - val_top-5-accuracy: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.7123 - accuracy: 0.7490 - top-5-accuracy: 0.9815 - val_loss: 0.4653 - val_accuracy: 0.8385 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.6756 - accuracy: 0.7562 - top-5-accuracy: 0.9805 - val_loss: 0.8704 - val_accuracy: 0.7205 - val_top-5-accuracy: 0.9441 - lr: 1.0000e-04\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.7675 - accuracy: 0.7233 - top-5-accuracy: 0.9825 - val_loss: 0.8032 - val_accuracy: 0.7143 - val_top-5-accuracy: 0.9565 - lr: 1.0000e-04\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.7483 - accuracy: 0.7459 - top-5-accuracy: 0.9733 - val_loss: 0.4953 - val_accuracy: 0.8323 - val_top-5-accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.6343 - accuracy: 0.7726 - top-5-accuracy: 0.9835 - val_loss: 0.5601 - val_accuracy: 0.8137 - val_top-5-accuracy: 0.9752 - lr: 1.0000e-04\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.5815 - accuracy: 0.7901 - top-5-accuracy: 0.9907 - val_loss: 0.5072 - val_accuracy: 0.8323 - val_top-5-accuracy: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.5372 - accuracy: 0.8076 - top-5-accuracy: 0.9897 - val_loss: 0.4846 - val_accuracy: 0.8447 - val_top-5-accuracy: 0.9689 - lr: 3.0000e-05\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 3s 173ms/step - loss: 0.5196 - accuracy: 0.8230 - top-5-accuracy: 0.9887 - val_loss: 0.4608 - val_accuracy: 0.8571 - val_top-5-accuracy: 0.9876 - lr: 3.0000e-05\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 3s 174ms/step - loss: 0.4821 - accuracy: 0.8385 - top-5-accuracy: 0.9918 - val_loss: 0.3942 - val_accuracy: 0.8634 - val_top-5-accuracy: 0.9876 - lr: 3.0000e-05\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 3s 175ms/step - loss: 0.4667 - accuracy: 0.8313 - top-5-accuracy: 0.9897 - val_loss: 0.4205 - val_accuracy: 0.8758 - val_top-5-accuracy: 0.9876 - lr: 3.0000e-05\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.4520 - accuracy: 0.8519 - top-5-accuracy: 0.9949 - val_loss: 0.3894 - val_accuracy: 0.8385 - val_top-5-accuracy: 0.9876 - lr: 3.0000e-05\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.4273 - accuracy: 0.8447 - top-5-accuracy: 0.9918 - val_loss: 0.4123 - val_accuracy: 0.8571 - val_top-5-accuracy: 0.9876 - lr: 3.0000e-05\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.4321 - accuracy: 0.8580 - top-5-accuracy: 0.9949 - val_loss: 0.3928 - val_accuracy: 0.8571 - val_top-5-accuracy: 0.9876 - lr: 3.0000e-05\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 3s 176ms/step - loss: 0.4033 - accuracy: 0.8611 - top-5-accuracy: 0.9938 - val_loss: 0.4132 - val_accuracy: 0.8882 - val_top-5-accuracy: 0.9814 - lr: 3.0000e-05\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 3s 176ms/step - loss: 0.3939 - accuracy: 0.8673 - top-5-accuracy: 0.9928 - val_loss: 0.3944 - val_accuracy: 0.8944 - val_top-5-accuracy: 0.9876 - lr: 3.0000e-05\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.3873 - accuracy: 0.8714 - top-5-accuracy: 0.9949 - val_loss: 0.3656 - val_accuracy: 0.8758 - val_top-5-accuracy: 0.9938 - lr: 3.0000e-05\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.3813 - accuracy: 0.8580 - top-5-accuracy: 0.9938 - val_loss: 0.4891 - val_accuracy: 0.8509 - val_top-5-accuracy: 0.9876 - lr: 3.0000e-05\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.3638 - accuracy: 0.8879 - top-5-accuracy: 0.9928 - val_loss: 0.4201 - val_accuracy: 0.8696 - val_top-5-accuracy: 0.9938 - lr: 3.0000e-05\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.3540 - accuracy: 0.8745 - top-5-accuracy: 0.9959 - val_loss: 0.4354 - val_accuracy: 0.8758 - val_top-5-accuracy: 0.9938 - lr: 3.0000e-05\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.3838 - accuracy: 0.8652 - top-5-accuracy: 0.9938 - val_loss: 0.4887 - val_accuracy: 0.8323 - val_top-5-accuracy: 0.9814 - lr: 3.0000e-05\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.3830 - accuracy: 0.8663 - top-5-accuracy: 0.9959 - val_loss: 0.4503 - val_accuracy: 0.8634 - val_top-5-accuracy: 0.9752 - lr: 3.0000e-05\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.3314 - accuracy: 0.8920 - top-5-accuracy: 0.9959 - val_loss: 0.4164 - val_accuracy: 0.8696 - val_top-5-accuracy: 0.9938 - lr: 9.0000e-06\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.2991 - accuracy: 0.8951 - top-5-accuracy: 0.9969 - val_loss: 0.3886 - val_accuracy: 0.8758 - val_top-5-accuracy: 0.9938 - lr: 9.0000e-06\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.2800 - accuracy: 0.9023 - top-5-accuracy: 0.9969 - val_loss: 0.4112 - val_accuracy: 0.8820 - val_top-5-accuracy: 0.9938 - lr: 9.0000e-06\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.2794 - accuracy: 0.9084 - top-5-accuracy: 0.9969 - val_loss: 0.4471 - val_accuracy: 0.8696 - val_top-5-accuracy: 0.9938 - lr: 9.0000e-06\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.2962 - accuracy: 0.9023 - top-5-accuracy: 0.9990 - val_loss: 0.5024 - val_accuracy: 0.8634 - val_top-5-accuracy: 0.9876 - lr: 9.0000e-06\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 2s 138ms/step - loss: 0.2796 - accuracy: 0.9105 - top-5-accuracy: 0.9969 - val_loss: 0.3506 - val_accuracy: 0.8820 - val_top-5-accuracy: 1.0000 - lr: 2.7000e-06\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.2752 - accuracy: 0.9105 - top-5-accuracy: 0.9949 - val_loss: 0.3956 - val_accuracy: 0.8758 - val_top-5-accuracy: 0.9938 - lr: 2.7000e-06\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.2620 - accuracy: 0.9095 - top-5-accuracy: 0.9990 - val_loss: 0.3793 - val_accuracy: 0.8820 - val_top-5-accuracy: 0.9938 - lr: 2.7000e-06\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.2640 - accuracy: 0.9126 - top-5-accuracy: 0.9979 - val_loss: 0.3710 - val_accuracy: 0.8696 - val_top-5-accuracy: 1.0000 - lr: 2.7000e-06\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.2655 - accuracy: 0.9084 - top-5-accuracy: 0.9959 - val_loss: 0.3868 - val_accuracy: 0.8758 - val_top-5-accuracy: 0.9938 - lr: 2.7000e-06\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.2579 - accuracy: 0.9146 - top-5-accuracy: 0.9959 - val_loss: 0.3799 - val_accuracy: 0.8820 - val_top-5-accuracy: 0.9938 - lr: 2.7000e-06\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.2611 - accuracy: 0.9105 - top-5-accuracy: 0.9969 - val_loss: 0.3763 - val_accuracy: 0.8820 - val_top-5-accuracy: 0.9938 - lr: 1.0000e-06\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.2572 - accuracy: 0.9249 - top-5-accuracy: 0.9979 - val_loss: 0.3691 - val_accuracy: 0.8820 - val_top-5-accuracy: 0.9938 - lr: 1.0000e-06\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.2509 - accuracy: 0.9156 - top-5-accuracy: 0.9990 - val_loss: 0.3634 - val_accuracy: 0.8758 - val_top-5-accuracy: 0.9938 - lr: 1.0000e-06\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.2846 - accuracy: 0.6377 - top-5-accuracy: 0.9443\n",
            "TRAIN RESULT : \n",
            "organmnist3d/tl:True/p:16\n",
            "    Test accuracy: 63.77%\n",
            "    Test top 5 accuracy: 94.43%\n",
            "Epoch 1/60\n",
            "19/19 [==============================] - 15s 233ms/step - loss: 0.6868 - accuracy: 0.6960 - top-5-accuracy: 1.0000 - val_loss: 0.5666 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 2/60\n",
            "19/19 [==============================] - 3s 141ms/step - loss: 0.5696 - accuracy: 0.7444 - top-5-accuracy: 1.0000 - val_loss: 0.5570 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 3/60\n",
            "19/19 [==============================] - 3s 138ms/step - loss: 0.5624 - accuracy: 0.7453 - top-5-accuracy: 1.0000 - val_loss: 0.5542 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 4/60\n",
            "19/19 [==============================] - 3s 142ms/step - loss: 0.5897 - accuracy: 0.7375 - top-5-accuracy: 1.0000 - val_loss: 0.5579 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 5/60\n",
            "19/19 [==============================] - 3s 140ms/step - loss: 0.5732 - accuracy: 0.7461 - top-5-accuracy: 1.0000 - val_loss: 0.5527 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 6/60\n",
            "19/19 [==============================] - 3s 137ms/step - loss: 0.5516 - accuracy: 0.7453 - top-5-accuracy: 1.0000 - val_loss: 0.5919 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 7/60\n",
            "19/19 [==============================] - 3s 168ms/step - loss: 0.5574 - accuracy: 0.7444 - top-5-accuracy: 1.0000 - val_loss: 0.5912 - val_accuracy: 0.7576 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 8/60\n",
            "19/19 [==============================] - 3s 138ms/step - loss: 0.5899 - accuracy: 0.7228 - top-5-accuracy: 1.0000 - val_loss: 0.5420 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 9/60\n",
            "19/19 [==============================] - 3s 170ms/step - loss: 0.5013 - accuracy: 0.7703 - top-5-accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.8061 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 10/60\n",
            "19/19 [==============================] - 3s 171ms/step - loss: 0.4545 - accuracy: 0.7962 - top-5-accuracy: 1.0000 - val_loss: 0.3845 - val_accuracy: 0.8545 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 11/60\n",
            "19/19 [==============================] - 3s 142ms/step - loss: 0.4303 - accuracy: 0.8100 - top-5-accuracy: 1.0000 - val_loss: 0.3884 - val_accuracy: 0.8364 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 12/60\n",
            "19/19 [==============================] - 3s 166ms/step - loss: 0.4181 - accuracy: 0.8204 - top-5-accuracy: 1.0000 - val_loss: 0.3627 - val_accuracy: 0.8727 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 13/60\n",
            "19/19 [==============================] - 3s 140ms/step - loss: 0.4091 - accuracy: 0.8256 - top-5-accuracy: 1.0000 - val_loss: 0.4225 - val_accuracy: 0.8303 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 14/60\n",
            "19/19 [==============================] - 3s 169ms/step - loss: 0.4218 - accuracy: 0.8230 - top-5-accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.8545 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 15/60\n",
            "19/19 [==============================] - 3s 170ms/step - loss: 0.4069 - accuracy: 0.8359 - top-5-accuracy: 1.0000 - val_loss: 0.3698 - val_accuracy: 0.8606 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 16/60\n",
            "19/19 [==============================] - 3s 142ms/step - loss: 0.3973 - accuracy: 0.8264 - top-5-accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.8364 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 17/60\n",
            "19/19 [==============================] - 3s 141ms/step - loss: 0.3764 - accuracy: 0.8489 - top-5-accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.8545 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 18/60\n",
            "19/19 [==============================] - 3s 137ms/step - loss: 0.3686 - accuracy: 0.8532 - top-5-accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.8667 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 19/60\n",
            "19/19 [==============================] - 3s 138ms/step - loss: 0.3456 - accuracy: 0.8627 - top-5-accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.8424 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 20/60\n",
            "19/19 [==============================] - 2s 134ms/step - loss: 0.3358 - accuracy: 0.8610 - top-5-accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.8424 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 21/60\n",
            "19/19 [==============================] - 3s 138ms/step - loss: 0.3245 - accuracy: 0.8713 - top-5-accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.8667 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 22/60\n",
            "19/19 [==============================] - 3s 140ms/step - loss: 0.2996 - accuracy: 0.8791 - top-5-accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 23/60\n",
            "19/19 [==============================] - 3s 137ms/step - loss: 0.2967 - accuracy: 0.8731 - top-5-accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.8545 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 24/60\n",
            "19/19 [==============================] - 3s 139ms/step - loss: 0.2992 - accuracy: 0.8791 - top-5-accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 25/60\n",
            "19/19 [==============================] - 3s 139ms/step - loss: 0.2930 - accuracy: 0.8877 - top-5-accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.8485 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 26/60\n",
            "19/19 [==============================] - 2s 135ms/step - loss: 0.2379 - accuracy: 0.9050 - top-5-accuracy: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.8424 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 27/60\n",
            "19/19 [==============================] - 3s 139ms/step - loss: 0.2566 - accuracy: 0.9016 - top-5-accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.8364 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 28/60\n",
            "19/19 [==============================] - 2s 135ms/step - loss: 0.2099 - accuracy: 0.9206 - top-5-accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.8303 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 29/60\n",
            "19/19 [==============================] - 3s 139ms/step - loss: 0.1505 - accuracy: 0.9344 - top-5-accuracy: 1.0000 - val_loss: 0.6528 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 30/60\n",
            "19/19 [==============================] - 3s 140ms/step - loss: 0.1433 - accuracy: 0.9482 - top-5-accuracy: 1.0000 - val_loss: 0.6754 - val_accuracy: 0.8545 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 31/60\n",
            "19/19 [==============================] - 3s 141ms/step - loss: 0.1311 - accuracy: 0.9473 - top-5-accuracy: 1.0000 - val_loss: 0.6716 - val_accuracy: 0.8303 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 32/60\n",
            "19/19 [==============================] - 3s 139ms/step - loss: 0.1102 - accuracy: 0.9620 - top-5-accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.8485 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 33/60\n",
            "19/19 [==============================] - 3s 142ms/step - loss: 0.0846 - accuracy: 0.9724 - top-5-accuracy: 1.0000 - val_loss: 0.8815 - val_accuracy: 0.8303 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 34/60\n",
            "19/19 [==============================] - 3s 137ms/step - loss: 0.0854 - accuracy: 0.9663 - top-5-accuracy: 1.0000 - val_loss: 0.6926 - val_accuracy: 0.8485 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 35/60\n",
            "19/19 [==============================] - 3s 140ms/step - loss: 0.0631 - accuracy: 0.9793 - top-5-accuracy: 1.0000 - val_loss: 0.7924 - val_accuracy: 0.8364 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 36/60\n",
            "19/19 [==============================] - 3s 137ms/step - loss: 0.0529 - accuracy: 0.9810 - top-5-accuracy: 1.0000 - val_loss: 0.8505 - val_accuracy: 0.8303 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 37/60\n",
            "19/19 [==============================] - 3s 138ms/step - loss: 0.0430 - accuracy: 0.9870 - top-5-accuracy: 1.0000 - val_loss: 0.9312 - val_accuracy: 0.8364 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 38/60\n",
            "19/19 [==============================] - 3s 143ms/step - loss: 0.0360 - accuracy: 0.9845 - top-5-accuracy: 1.0000 - val_loss: 1.0139 - val_accuracy: 0.8364 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.3515 - accuracy: 0.8484 - top-5-accuracy: 1.0000\n",
            "TRAIN RESULT : \n",
            "nodulemnist3d/tl:False/p:8\n",
            "    Test accuracy: 84.84%\n",
            "    Test top 5 accuracy: 100.0%\n",
            "Epoch 1/60\n",
            "19/19 [==============================] - 16s 243ms/step - loss: 0.6946 - accuracy: 0.7073 - top-5-accuracy: 1.0000 - val_loss: 0.5711 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 2/60\n",
            "19/19 [==============================] - 3s 137ms/step - loss: 0.5969 - accuracy: 0.7375 - top-5-accuracy: 1.0000 - val_loss: 0.5615 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 3/60\n",
            "19/19 [==============================] - 3s 139ms/step - loss: 0.5668 - accuracy: 0.7453 - top-5-accuracy: 1.0000 - val_loss: 0.5626 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 4/60\n",
            "19/19 [==============================] - 3s 141ms/step - loss: 0.5644 - accuracy: 0.7453 - top-5-accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 5/60\n",
            "19/19 [==============================] - 3s 139ms/step - loss: 0.5614 - accuracy: 0.7453 - top-5-accuracy: 1.0000 - val_loss: 0.5556 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 6/60\n",
            "19/19 [==============================] - 2s 133ms/step - loss: 0.5622 - accuracy: 0.7444 - top-5-accuracy: 1.0000 - val_loss: 0.5534 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 7/60\n",
            "19/19 [==============================] - 3s 138ms/step - loss: 0.5755 - accuracy: 0.7487 - top-5-accuracy: 1.0000 - val_loss: 0.5636 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 8/60\n",
            "19/19 [==============================] - 3s 139ms/step - loss: 0.5629 - accuracy: 0.7453 - top-5-accuracy: 1.0000 - val_loss: 0.5496 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 9/60\n",
            "19/19 [==============================] - 3s 169ms/step - loss: 0.5640 - accuracy: 0.7453 - top-5-accuracy: 1.0000 - val_loss: 0.5629 - val_accuracy: 0.7576 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 10/60\n",
            "19/19 [==============================] - 3s 138ms/step - loss: 0.5607 - accuracy: 0.7461 - top-5-accuracy: 1.0000 - val_loss: 0.5358 - val_accuracy: 0.7576 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 11/60\n",
            "19/19 [==============================] - 3s 136ms/step - loss: 0.5434 - accuracy: 0.7513 - top-5-accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.7515 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 12/60\n",
            "19/19 [==============================] - 3s 137ms/step - loss: 0.5063 - accuracy: 0.7435 - top-5-accuracy: 1.0000 - val_loss: 0.4543 - val_accuracy: 0.7515 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 13/60\n",
            "19/19 [==============================] - 3s 170ms/step - loss: 0.5172 - accuracy: 0.7530 - top-5-accuracy: 1.0000 - val_loss: 0.4175 - val_accuracy: 0.8485 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 14/60\n",
            "19/19 [==============================] - 3s 172ms/step - loss: 0.4437 - accuracy: 0.8092 - top-5-accuracy: 1.0000 - val_loss: 0.3812 - val_accuracy: 0.8545 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 15/60\n",
            "19/19 [==============================] - 3s 141ms/step - loss: 0.4312 - accuracy: 0.8195 - top-5-accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.8545 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 16/60\n",
            "19/19 [==============================] - 3s 135ms/step - loss: 0.4130 - accuracy: 0.8351 - top-5-accuracy: 1.0000 - val_loss: 0.3868 - val_accuracy: 0.8424 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 17/60\n",
            "19/19 [==============================] - 3s 137ms/step - loss: 0.4055 - accuracy: 0.8411 - top-5-accuracy: 1.0000 - val_loss: 0.3790 - val_accuracy: 0.8545 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 18/60\n",
            "19/19 [==============================] - 3s 164ms/step - loss: 0.4021 - accuracy: 0.8299 - top-5-accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.8727 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 19/60\n",
            "19/19 [==============================] - 3s 138ms/step - loss: 0.4066 - accuracy: 0.8333 - top-5-accuracy: 1.0000 - val_loss: 0.3573 - val_accuracy: 0.8545 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 20/60\n",
            "19/19 [==============================] - 3s 146ms/step - loss: 0.3721 - accuracy: 0.8497 - top-5-accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 21/60\n",
            "19/19 [==============================] - 3s 139ms/step - loss: 0.3641 - accuracy: 0.8506 - top-5-accuracy: 1.0000 - val_loss: 0.3636 - val_accuracy: 0.8364 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 22/60\n",
            "19/19 [==============================] - 3s 145ms/step - loss: 0.3467 - accuracy: 0.8566 - top-5-accuracy: 1.0000 - val_loss: 0.3647 - val_accuracy: 0.8485 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 23/60\n",
            "19/19 [==============================] - 3s 147ms/step - loss: 0.3294 - accuracy: 0.8627 - top-5-accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.8061 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 24/60\n",
            "19/19 [==============================] - 3s 149ms/step - loss: 0.2931 - accuracy: 0.8921 - top-5-accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.7818 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 25/60\n",
            "19/19 [==============================] - 3s 136ms/step - loss: 0.2988 - accuracy: 0.8765 - top-5-accuracy: 1.0000 - val_loss: 0.5556 - val_accuracy: 0.8364 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 26/60\n",
            "19/19 [==============================] - 3s 143ms/step - loss: 0.2664 - accuracy: 0.8955 - top-5-accuracy: 1.0000 - val_loss: 0.5341 - val_accuracy: 0.8182 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 27/60\n",
            "19/19 [==============================] - 2s 134ms/step - loss: 0.2715 - accuracy: 0.9007 - top-5-accuracy: 1.0000 - val_loss: 0.5935 - val_accuracy: 0.8303 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 28/60\n",
            "19/19 [==============================] - 2s 134ms/step - loss: 0.2578 - accuracy: 0.9067 - top-5-accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.8182 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 29/60\n",
            "19/19 [==============================] - 2s 135ms/step - loss: 0.2537 - accuracy: 0.8990 - top-5-accuracy: 1.0000 - val_loss: 0.5563 - val_accuracy: 0.8000 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 30/60\n",
            "19/19 [==============================] - 3s 136ms/step - loss: 0.2281 - accuracy: 0.9119 - top-5-accuracy: 1.0000 - val_loss: 0.6067 - val_accuracy: 0.8000 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 31/60\n",
            "19/19 [==============================] - 3s 141ms/step - loss: 0.2282 - accuracy: 0.9076 - top-5-accuracy: 1.0000 - val_loss: 0.5502 - val_accuracy: 0.8061 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 32/60\n",
            "19/19 [==============================] - 3s 138ms/step - loss: 0.2142 - accuracy: 0.9188 - top-5-accuracy: 1.0000 - val_loss: 0.6305 - val_accuracy: 0.8000 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 33/60\n",
            "19/19 [==============================] - 3s 137ms/step - loss: 0.2154 - accuracy: 0.9111 - top-5-accuracy: 1.0000 - val_loss: 0.5963 - val_accuracy: 0.7939 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 34/60\n",
            "19/19 [==============================] - 2s 133ms/step - loss: 0.2009 - accuracy: 0.9223 - top-5-accuracy: 1.0000 - val_loss: 0.6728 - val_accuracy: 0.7818 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 35/60\n",
            "19/19 [==============================] - 3s 136ms/step - loss: 0.1865 - accuracy: 0.9257 - top-5-accuracy: 1.0000 - val_loss: 0.7058 - val_accuracy: 0.7939 - val_top-5-accuracy: 1.0000 - lr: 2.7000e-06\n",
            "Epoch 36/60\n",
            "19/19 [==============================] - 3s 138ms/step - loss: 0.1873 - accuracy: 0.9266 - top-5-accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.7758 - val_top-5-accuracy: 1.0000 - lr: 2.7000e-06\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.3434 - accuracy: 0.8484 - top-5-accuracy: 1.0000\n",
            "TRAIN RESULT : \n",
            "nodulemnist3d/tl:True/p:8\n",
            "    Test accuracy: 84.84%\n",
            "    Test top 5 accuracy: 100.0%\n",
            "Epoch 1/60\n",
            "19/19 [==============================] - 14s 211ms/step - loss: 0.8375 - accuracy: 0.6649 - top-5-accuracy: 1.0000 - val_loss: 0.5461 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 2/60\n",
            "19/19 [==============================] - 3s 148ms/step - loss: 0.5471 - accuracy: 0.7306 - top-5-accuracy: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.7636 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 3/60\n",
            "19/19 [==============================] - 3s 147ms/step - loss: 0.4924 - accuracy: 0.7781 - top-5-accuracy: 1.0000 - val_loss: 0.4490 - val_accuracy: 0.8000 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 4/60\n",
            "19/19 [==============================] - 2s 115ms/step - loss: 0.4840 - accuracy: 0.7910 - top-5-accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.7879 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 5/60\n",
            "19/19 [==============================] - 3s 167ms/step - loss: 0.4726 - accuracy: 0.8100 - top-5-accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.8364 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 6/60\n",
            "19/19 [==============================] - 2s 113ms/step - loss: 0.4599 - accuracy: 0.8066 - top-5-accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 7/60\n",
            "19/19 [==============================] - 2s 113ms/step - loss: 0.4565 - accuracy: 0.8152 - top-5-accuracy: 1.0000 - val_loss: 0.4794 - val_accuracy: 0.7939 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 8/60\n",
            "19/19 [==============================] - 2s 115ms/step - loss: 0.4789 - accuracy: 0.7867 - top-5-accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.8303 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 9/60\n",
            "19/19 [==============================] - 2s 115ms/step - loss: 0.4246 - accuracy: 0.8187 - top-5-accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.8303 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 10/60\n",
            "19/19 [==============================] - 3s 148ms/step - loss: 0.4199 - accuracy: 0.8273 - top-5-accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 0.8606 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 11/60\n",
            "19/19 [==============================] - 2s 120ms/step - loss: 0.4203 - accuracy: 0.8204 - top-5-accuracy: 1.0000 - val_loss: 0.3917 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 12/60\n",
            "19/19 [==============================] - 2s 114ms/step - loss: 0.3963 - accuracy: 0.8359 - top-5-accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 13/60\n",
            "19/19 [==============================] - 2s 113ms/step - loss: 0.3861 - accuracy: 0.8497 - top-5-accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.8424 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 14/60\n",
            "19/19 [==============================] - 2s 114ms/step - loss: 0.4195 - accuracy: 0.8195 - top-5-accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.8303 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 15/60\n",
            "19/19 [==============================] - 2s 115ms/step - loss: 0.3806 - accuracy: 0.8377 - top-5-accuracy: 1.0000 - val_loss: 0.3952 - val_accuracy: 0.8303 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 16/60\n",
            "19/19 [==============================] - 2s 117ms/step - loss: 0.3570 - accuracy: 0.8566 - top-5-accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.8364 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 17/60\n",
            "19/19 [==============================] - 2s 114ms/step - loss: 0.3582 - accuracy: 0.8584 - top-5-accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.8061 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 18/60\n",
            "19/19 [==============================] - 2s 118ms/step - loss: 0.3891 - accuracy: 0.8359 - top-5-accuracy: 1.0000 - val_loss: 0.4086 - val_accuracy: 0.8364 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 19/60\n",
            "19/19 [==============================] - 2s 115ms/step - loss: 0.3425 - accuracy: 0.8601 - top-5-accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.8424 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 20/60\n",
            "19/19 [==============================] - 2s 115ms/step - loss: 0.3140 - accuracy: 0.8748 - top-5-accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.8303 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 21/60\n",
            "19/19 [==============================] - 2s 116ms/step - loss: 0.3105 - accuracy: 0.8791 - top-5-accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.8303 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 22/60\n",
            "19/19 [==============================] - 2s 115ms/step - loss: 0.2920 - accuracy: 0.8860 - top-5-accuracy: 1.0000 - val_loss: 0.5198 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 23/60\n",
            "19/19 [==============================] - 2s 116ms/step - loss: 0.3023 - accuracy: 0.8843 - top-5-accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.8303 - val_top-5-accuracy: 1.0000 - lr: 3.0000e-05\n",
            "Epoch 24/60\n",
            "19/19 [==============================] - 2s 115ms/step - loss: 0.2789 - accuracy: 0.8921 - top-5-accuracy: 1.0000 - val_loss: 0.4604 - val_accuracy: 0.8303 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 25/60\n",
            "19/19 [==============================] - 2s 115ms/step - loss: 0.2730 - accuracy: 0.8938 - top-5-accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.8182 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 26/60\n",
            "19/19 [==============================] - 2s 114ms/step - loss: 0.2730 - accuracy: 0.8903 - top-5-accuracy: 1.0000 - val_loss: 0.4801 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 27/60\n",
            "19/19 [==============================] - 2s 115ms/step - loss: 0.2748 - accuracy: 0.8886 - top-5-accuracy: 1.0000 - val_loss: 0.4960 - val_accuracy: 0.8182 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 28/60\n",
            "19/19 [==============================] - 2s 112ms/step - loss: 0.2744 - accuracy: 0.8895 - top-5-accuracy: 1.0000 - val_loss: 0.5012 - val_accuracy: 0.8121 - val_top-5-accuracy: 1.0000 - lr: 9.0000e-06\n",
            "Epoch 29/60\n",
            "19/19 [==============================] - 2s 114ms/step - loss: 0.2634 - accuracy: 0.8938 - top-5-accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.8303 - val_top-5-accuracy: 1.0000 - lr: 2.7000e-06\n",
            "Epoch 30/60\n",
            "19/19 [==============================] - 2s 115ms/step - loss: 0.2648 - accuracy: 0.8895 - top-5-accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 2.7000e-06\n",
            "Epoch 31/60\n",
            "19/19 [==============================] - 2s 113ms/step - loss: 0.2579 - accuracy: 0.8972 - top-5-accuracy: 1.0000 - val_loss: 0.4774 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 2.7000e-06\n",
            "Epoch 32/60\n",
            "19/19 [==============================] - 2s 113ms/step - loss: 0.2607 - accuracy: 0.8946 - top-5-accuracy: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 2.7000e-06\n",
            "Epoch 33/60\n",
            "19/19 [==============================] - 2s 114ms/step - loss: 0.2560 - accuracy: 0.8955 - top-5-accuracy: 1.0000 - val_loss: 0.4912 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 2.7000e-06\n",
            "Epoch 34/60\n",
            "19/19 [==============================] - 2s 116ms/step - loss: 0.2529 - accuracy: 0.9007 - top-5-accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 35/60\n",
            "19/19 [==============================] - 2s 113ms/step - loss: 0.2569 - accuracy: 0.8981 - top-5-accuracy: 1.0000 - val_loss: 0.4932 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 36/60\n",
            "19/19 [==============================] - 2s 115ms/step - loss: 0.2544 - accuracy: 0.8964 - top-5-accuracy: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-06\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4281 - accuracy: 0.8323 - top-5-accuracy: 1.0000\n",
            "TRAIN RESULT : \n",
            "nodulemnist3d/tl:False/p:16\n",
            "    Test accuracy: 83.23%\n",
            "    Test top 5 accuracy: 100.0%\n",
            "Epoch 1/60\n",
            "19/19 [==============================] - 15s 252ms/step - loss: 0.8996 - accuracy: 0.6364 - top-5-accuracy: 1.0000 - val_loss: 0.6424 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 2/60\n",
            "19/19 [==============================] - 2s 119ms/step - loss: 0.5916 - accuracy: 0.7254 - top-5-accuracy: 1.0000 - val_loss: 0.5512 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 3/60\n",
            "19/19 [==============================] - 2s 119ms/step - loss: 0.5382 - accuracy: 0.7565 - top-5-accuracy: 1.0000 - val_loss: 0.5181 - val_accuracy: 0.7455 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 4/60\n",
            "19/19 [==============================] - 3s 154ms/step - loss: 0.5180 - accuracy: 0.7660 - top-5-accuracy: 1.0000 - val_loss: 0.4762 - val_accuracy: 0.7697 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 5/60\n",
            "19/19 [==============================] - 3s 157ms/step - loss: 0.4899 - accuracy: 0.7927 - top-5-accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.8061 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 6/60\n",
            "19/19 [==============================] - 3s 159ms/step - loss: 0.4794 - accuracy: 0.7979 - top-5-accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.8182 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 7/60\n",
            "19/19 [==============================] - 3s 158ms/step - loss: 0.4545 - accuracy: 0.8135 - top-5-accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.8424 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 8/60\n",
            "19/19 [==============================] - 2s 123ms/step - loss: 0.4728 - accuracy: 0.7979 - top-5-accuracy: 1.0000 - val_loss: 0.4040 - val_accuracy: 0.8303 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 9/60\n",
            "19/19 [==============================] - 2s 121ms/step - loss: 0.4504 - accuracy: 0.8083 - top-5-accuracy: 1.0000 - val_loss: 0.4479 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 10/60\n",
            "19/19 [==============================] - 2s 124ms/step - loss: 0.4472 - accuracy: 0.8135 - top-5-accuracy: 1.0000 - val_loss: 0.3895 - val_accuracy: 0.8424 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 11/60\n",
            "19/19 [==============================] - 3s 144ms/step - loss: 0.4440 - accuracy: 0.8135 - top-5-accuracy: 1.0000 - val_loss: 0.3934 - val_accuracy: 0.8424 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 12/60\n",
            "19/19 [==============================] - 3s 188ms/step - loss: 0.4125 - accuracy: 0.8333 - top-5-accuracy: 1.0000 - val_loss: 0.4067 - val_accuracy: 0.8364 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 13/60\n",
            "19/19 [==============================] - 3s 153ms/step - loss: 0.4044 - accuracy: 0.8325 - top-5-accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.8545 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 14/60\n",
            "19/19 [==============================] - 2s 123ms/step - loss: 0.4335 - accuracy: 0.8230 - top-5-accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.8061 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 15/60\n",
            "19/19 [==============================] - 2s 119ms/step - loss: 0.4299 - accuracy: 0.8143 - top-5-accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.8121 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 16/60\n",
            "19/19 [==============================] - 2s 123ms/step - loss: 0.4257 - accuracy: 0.8307 - top-5-accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.8242 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 17/60\n",
            "19/19 [==============================] - 2s 119ms/step - loss: 0.3766 - accuracy: 0.8463 - top-5-accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.8364 - val_top-5-accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 18/60\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.3742 - accuracy: 0.8463 - top-5-accuracy: 1.0000"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View & Upload on TensorBoard"
      ],
      "metadata": {
        "id": "RKNUFdUuWqFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View TensorBoard\n",
        "%tensorboard --logdir logs/fit"
      ],
      "metadata": {
        "id": "F0xaShDm-Jce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload an experiment:\n",
        "!tensorboard dev upload --logdir logs \\\n",
        "    --name \"ViViT with/without Token Learner\" \\\n",
        "    --description \"Comparison between ViViT with and without Token Learner.\""
      ],
      "metadata": {
        "id": "_tX7_3DbWv_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf5839fe-66cd-49ca-e4c0-1a6b35674625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload started and will continue reading any new data as it's added to the logdir.\n",
            "\n",
            "To stop uploading, press Ctrl-C.\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/nYVP58K4Q1GEuWLbkWBFow/\n",
            "\n",
            "\u001b[1m[2023-01-18T11:08:25]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2023-01-18T11:09:44]\u001b[0m Total uploaded: 3393 scalars, 52053 tensors (36.5 MB), 8 binary objects (9.9 MB)\n"
          ]
        }
      ]
    }
  ]
}